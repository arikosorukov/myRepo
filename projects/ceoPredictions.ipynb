{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T02:45:11.438004100Z",
     "start_time": "2023-07-16T02:45:11.320467200Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\Ari\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\lib\\nvfuser_codegen.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\__init__.py:122\u001B[0m\n\u001B[0;32m    120\u001B[0m     err \u001B[38;5;241m=\u001B[39m ctypes\u001B[38;5;241m.\u001B[39mWinError(last_error)\n\u001B[0;32m    121\u001B[0m     err\u001B[38;5;241m.\u001B[39mstrerror \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m Error loading \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdll\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m or one of its dependencies.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m     is_loaded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mOSError\u001B[0m: [WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\Ari\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\lib\\nvfuser_codegen.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\Ari\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\lib\\nvfuser_codegen.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      3\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available()\n\u001B[0;32m      5\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice_count()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\__init__.py:122\u001B[0m\n\u001B[0;32m    120\u001B[0m     err \u001B[38;5;241m=\u001B[39m ctypes\u001B[38;5;241m.\u001B[39mWinError(last_error)\n\u001B[0;32m    121\u001B[0m     err\u001B[38;5;241m.\u001B[39mstrerror \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m Error loading \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdll\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m or one of its dependencies.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m     is_loaded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mOSError\u001B[0m: [WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\Ari\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\lib\\nvfuser_codegen.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    ">>> import torch\n",
    "\n",
    ">>> torch.cuda.is_available()\n",
    "\n",
    ">>> torch.cuda.device_count()\n",
    "\n",
    ">>> torch.cuda.current_device()\n",
    "\n",
    ">>> torch.cuda.device(0)\n",
    "\n",
    ">>> torch.cuda.get_device_name(0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T02:45:15.568708900Z",
     "start_time": "2023-07-16T02:45:15.464177700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the trainingsample CSV dataset:\n",
    "* \"Content\": the CEO's announcement\n",
    "* \"Content_Length\": the number of words in the CEO's announcement\n",
    "* \"product_related\": the label indicating whether the announcement is product-related or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T02:45:22.893135500Z",
     "start_time": "2023-07-16T02:45:22.845617800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                             Content  Content_Length  \\\n0  The benefits I think we will see from the chan...              55   \n1  I would just add one more thing. While we shou...              64   \n2  Ken, I don't have that number at my fingertips...              51   \n3  I think the only part of the segment that I di...             137   \n4  No, nothing has changed. I have been an invest...              75   \n\n  product_related  \n0              No  \n1              No  \n2              No  \n3             Yes  \n4              No  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Content</th>\n      <th>Content_Length</th>\n      <th>product_related</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The benefits I think we will see from the chan...</td>\n      <td>55</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I would just add one more thing. While we shou...</td>\n      <td>64</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ken, I don't have that number at my fingertips...</td>\n      <td>51</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I think the only part of the segment that I di...</td>\n      <td>137</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>No, nothing has changed. I have been an invest...</td>\n      <td>75</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sample = pd.read_csv(\"Data/trainingsample.csv\")\n",
    "training_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T22:12:48.057654100Z",
     "start_time": "2023-07-15T22:12:48.040600600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Length</th>\n",
       "      <th>product_related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The benefits I think we will see from the chan...</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would just add one more thing. While we shou...</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ken, I don't have that number at my fingertips...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think the only part of the segment that I di...</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No, nothing has changed. I have been an invest...</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Content_Length  \\\n",
       "0  The benefits I think we will see from the chan...              55   \n",
       "1  I would just add one more thing. While we shou...              64   \n",
       "2  Ken, I don't have that number at my fingertips...              51   \n",
       "3  I think the only part of the segment that I di...             137   \n",
       "4  No, nothing has changed. I have been an invest...              75   \n",
       "\n",
       "   product_related  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                1  \n",
       "4                0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the product_related column, convert Yes/No labels to binary 1/0\n",
    "training_sample = training_sample.replace({'product_related': {'No': 0, 'Yes': 1}})\n",
    "training_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T00:33:44.069359500Z",
     "start_time": "2023-07-16T00:33:44.055075700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1    0.58\n0    0.42\nName: product_related, dtype: float64"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class distribution\n",
    "training_sample['product_related'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Split  data into training and testing (80/20)\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(\n",
    "                                                training_sample['Content'],\n",
    "                                                training_sample['product_related'],\n",
    "                                                random_state = 2023,\n",
    "                                                test_size= 0.2)\n",
    "\n",
    "# Split the training data into training and validation (again, 80/20 is a fair split).\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(\n",
    "                                            temp_text, temp_labels,\n",
    "                                            random_state = 2023,\n",
    "                                            test_size= 0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T01:26:21.714290Z",
     "start_time": "2023-07-16T01:26:21.704288600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cedab160580425380bec8f7cff435cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ari\\anaconda3\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ari\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1f5239d55844bfd97c956a85f8fd351"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T02:02:48.582741500Z",
     "start_time": "2023-07-16T02:02:15.923435600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a378dd10ded4ea2bffcd39d38580b97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "141cbea7993f4588aa27b78fe2968166"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "afa1e84090c840d1acf4cba7e0d00c28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T02:03:04.561580Z",
     "start_time": "2023-07-16T02:03:03.358789100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: >"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# length of all messages in the dataset\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "pd.Series(seq_len).hist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T02:04:50.286730200Z",
     "start_time": "2023-07-16T02:04:50.163302800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ari\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T02:05:20.101061100Z",
     "start_time": "2023-07-16T02:05:20.044724700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# convert lists to tensors\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T02:06:05.283348600Z",
     "start_time": "2023-07-16T02:06:05.272461300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T02:06:08.070997400Z",
     "start_time": "2023-07-16T02:06:08.060585300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T02:06:21.362113800Z",
     "start_time": "2023-07-16T02:06:21.330860800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "\n",
    "        self.bert = bert\n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "\n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "        #pass the inputs to the model\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "\n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T02:06:30.988607100Z",
     "start_time": "2023-07-16T02:06:30.988607100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),lr = 1e-5)#%%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exploring the trainingsample CSV dataset:\n",
    "* \"Content\": the CEO's announcement\n",
    "* \"Content_Length\": the number of words in the CEO's announcement\n",
    "* \"product_related\": the label indicating whether the announcement is product-related or not\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_sample = pd.read_csv(\"Data/trainingsample.csv\")\n",
    "training_sample.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# In the product_related column, convert Yes/No labels to binary 1/0\n",
    "training_sample = training_sample.replace({'product_related': {'No': 0, 'Yes': 1}})\n",
    "training_sample.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check class distribution\n",
    "training_sample['product_related'].value_counts(normalize = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split  data into training and testing (80/20)\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(\n",
    "                                                training_sample['Content'],\n",
    "                                                training_sample['product_related'],\n",
    "                                                random_state = 2023,\n",
    "                                                test_size= 0.2)\n",
    "\n",
    "# Split the training data into training and validation (again, 80/20 is a fair split).\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(\n",
    "                                            temp_text, temp_labels,\n",
    "                                            random_state = 2023,\n",
    "                                            test_size= 0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# length of all messages in the dataset\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "pd.Series(seq_len).hist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert lists to tensors\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T02:07:23.764796500Z",
     "start_time": "2023-07-16T02:07:23.750986800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "\n",
    "        self.bert = bert\n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "\n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "        #pass the inputs to the model\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "\n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T02:07:25.436585400Z",
     "start_time": "2023-07-16T02:07:25.417383200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[50], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m BERT_Arch(bert)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# push the model to GPU\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1141\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1142\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[1;32m-> 1145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 797\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    800\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    801\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    802\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    808\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 797\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    800\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    801\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    802\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    808\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 797\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    800\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    801\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    802\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    808\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    816\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    818\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    819\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 820\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    821\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m   1140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m   1141\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1142\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m-> 1143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\cuda\\__init__.py:239\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    236\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    237\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 239\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    242\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T02:07:31.565136800Z",
     "start_time": "2023-07-16T02:07:31.105051400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),lr = 1e-5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_class_weight() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[64], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclass_weight\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compute_class_weight\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#compute the class weights\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m class_weights \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_class_weight\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbalanced\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munique\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClass Weights:\u001B[39m\u001B[38;5;124m\"\u001B[39m,class_weights)\n",
      "\u001B[1;31mTypeError\u001B[0m: compute_class_weight() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_weights = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
    "\n",
    "print(\"Class Weights:\",class_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T02:20:36.851723500Z",
     "start_time": "2023-07-16T02:20:36.830270300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights)\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
